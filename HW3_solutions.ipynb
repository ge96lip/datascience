{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3: Regression and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will preprocess the dataset and perform some basic regression and classification tasks. The learning outcome of this part is to know how one can pre-process a real-world dataset and perform a supervised learning task, and to understand some of the fundamental mechanisms behind these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student information\n",
    "Please provide your information for automatic grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "STUD_SUID = 'lika3203'\n",
    "STUD_NAME = 'Linn Karlsson'\n",
    "STUD_EMAIL = 'lika3203@student.su.se'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Grading: \n",
    "\n",
    "Pass/Fail.\n",
    "\n",
    "To Pass this HW you need to provide a complete and correct solution, where one minor mistake is allowed. However, if your solution has more minor mistakes or lacks parts entirely or has one or more major mistakes, then you receive a Fail grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTLINE: \n",
    "\n",
    "Data pre-processing, regression task and classification task\n",
    "\n",
    "1. Reading the files\n",
    "2. Missing Values\n",
    "3. Imputing categorical variables\n",
    "4. Imputing numerical variables\n",
    "5. Classification with Decision Tree, single split\n",
    "6. Classification with Decision Tree, Cross validation\n",
    "7. Interpretation of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important instructions:\n",
    "\n",
    "Each function you make will be considered during the grading, so it is important to strictly follow input and output instructions stated in the skeleton code.\n",
    "\n",
    "You must not delete any of the given cells or change the structure of the cells or change the instructions in the cells or add cells (unless completely necessary, add a comment on why you added a cell) as they will help in grading the assignment. Should you contravene this provision, you will fail the assignment, and no feedback will be given on the part after the contravention.\n",
    "\n",
    "Some variable names are already given and have random values or empty arrays assigned on them. In this case you should only change the assignments on the variables but keep the names as given.\n",
    "\n",
    "When you are finished with implementing all the tasks, **clear all outputs, run all cells again** (make sure there is no error) and submit!\n",
    "\n",
    "Make sure that the results and figures asked are visible for us to grade.\n",
    "\n",
    "Make sure not to modify the files in the \"data\" folder in your submission, and not to change the folder structure or the files location, or your submission will not obtain a passing grade."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure consistent results, make sure that every operation in which you can use a random seed has it set to 8. If your process is correct, but the results are wrong due to the seed being wrong, it will be considered a major mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the libraries that you will need throughout the assignment\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "RSEED = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *1.* Reading the files\n",
    "\n",
    "### `Task: Read the datasets using pandas. Use the files called cleveland.data and switzerland.data that you have downloaded in this archive.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets contain information about adult patients from the US and from Switzerland. You can find more information in the heart-disease.names file in the 'data' folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the folder 'data', read the files cleveland.data and switzerland.data into the dataframes cleveland and test, respectively.\n",
    "# Make sure to add the names of the variables to both dataframes.\n",
    "\n",
    "columns = ['age', 'sex', 'cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal','num'] # you can find the column names in the file 'data/heart-disease.names'.\n",
    "# Select the correct column names for the dataset, as described in the file.\n",
    "\n",
    "\n",
    "cleveland = pd.read_csv(\"../data/cleveland.data\", names=columns)\n",
    "test = pd.read_csv(\"../data/switzerland.data\", names=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca thal  num  \n",
       "0    3.0  0.0  6.0    0  \n",
       "1    2.0  3.0  3.0    2  \n",
       "2    2.0  2.0  7.0    1  \n",
       "3    3.0  0.0  3.0    0  \n",
       "4    1.0  0.0  3.0    0  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not delete this!\n",
    "cleveland.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>?</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps  chol fbs restecg  thalach  exang  oldpeak slope  \\\n",
       "0  32.0  1.0  1.0      95.0   0.0   ?       0    127.0    0.0      0.7     1   \n",
       "1  34.0  1.0  4.0     115.0   0.0   ?       ?    154.0    0.0      0.2     1   \n",
       "2  36.0  1.0  4.0     110.0   0.0   ?       0    125.0    1.0      1.0     2   \n",
       "3  38.0  0.0  4.0     105.0   0.0   ?       0    166.0    0.0      2.8     1   \n",
       "4  38.0  0.0  4.0     110.0   0.0   0       0    156.0    0.0      0.0     2   \n",
       "\n",
       "  ca thal  num  \n",
       "0  ?    ?  1.0  \n",
       "1  ?    ?  1.0  \n",
       "2  ?    6  1.0  \n",
       "3  ?    ?  2.0  \n",
       "4  ?    3  1.0  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not delete this!\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60.270627</td>\n",
       "      <td>0.679868</td>\n",
       "      <td>3.158416</td>\n",
       "      <td>131.689769</td>\n",
       "      <td>246.693069</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.990099</td>\n",
       "      <td>149.607261</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.600660</td>\n",
       "      <td>0.937294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>77.296578</td>\n",
       "      <td>0.467299</td>\n",
       "      <td>0.960126</td>\n",
       "      <td>17.599748</td>\n",
       "      <td>51.776918</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.994971</td>\n",
       "      <td>22.875003</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.228536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>275.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    60.270627    0.679868    3.158416  131.689769  246.693069    0.148515   \n",
       "std     77.296578    0.467299    0.960126   17.599748   51.776918    0.356198   \n",
       "min      0.000000    0.000000    1.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    3.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    3.000000  130.000000  241.000000    0.000000   \n",
       "75%     61.000000    1.000000    4.000000  140.000000  275.000000    0.000000   \n",
       "max    999.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope         num  \n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000  \n",
       "mean     0.990099  149.607261    0.326733    1.039604    1.600660    0.937294  \n",
       "std      0.994971   22.875003    0.469794    1.161075    0.616226    1.228536  \n",
       "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000  \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000  \n",
       "50%      1.000000  153.000000    0.000000    0.800000    2.000000    0.000000  \n",
       "75%      2.000000  166.000000    1.000000    1.600000    2.000000    2.000000  \n",
       "max      2.000000  202.000000    1.000000    6.200000    3.000000    4.000000  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to see information about the dataset, uncomment:\n",
    "cleveland.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>122.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.0</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>82.409836</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>3.683761</td>\n",
       "      <td>129.957265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122.299145</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>1.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>170.211621</td>\n",
       "      <td>0.280782</td>\n",
       "      <td>0.702822</td>\n",
       "      <td>22.423200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.759921</td>\n",
       "      <td>0.498007</td>\n",
       "      <td>1.056061</td>\n",
       "      <td>1.011866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>48.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps   chol     thalach  \\\n",
       "count  122.000000  117.000000  117.000000  117.000000  117.0  117.000000   \n",
       "mean    82.409836    0.914530    3.683761  129.957265    0.0  122.299145   \n",
       "std    170.211621    0.280782    0.702822   22.423200    0.0   25.759921   \n",
       "min      0.000000    0.000000    1.000000   80.000000    0.0   60.000000   \n",
       "25%     48.500000    1.000000    4.000000  115.000000    0.0  105.000000   \n",
       "50%     56.000000    1.000000    4.000000  125.000000    0.0  121.000000   \n",
       "75%     61.000000    1.000000    4.000000  145.000000    0.0  141.000000   \n",
       "max    999.000000    1.000000    4.000000  200.000000    0.0  182.000000   \n",
       "\n",
       "            exang     oldpeak         num  \n",
       "count  117.000000  117.000000  117.000000  \n",
       "mean     0.435897    0.653846    1.769231  \n",
       "std      0.498007    1.056061    1.011866  \n",
       "min      0.000000   -2.600000    0.000000  \n",
       "25%      0.000000    0.000000    1.000000  \n",
       "50%      0.000000    0.300000    2.000000  \n",
       "75%      1.000000    1.500000    3.000000  \n",
       "max      1.000000    3.700000    4.000000  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you want to see information about the dataset, uncomment:\n",
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *2.* Missing values\n",
    "\n",
    "### `Task: Produce a plot with two subplots, each showing a bar plot of the 'missing' values (either encoded as NaN, or encoded with values that should not be in the dataset) for each feature for the two dataframes. The plot must have a name, and the bars must be named using the feature names.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(age         0\n",
       " sex         0\n",
       " cp          0\n",
       " trestbps    0\n",
       " chol        0\n",
       " fbs         0\n",
       " restecg     0\n",
       " thalach     0\n",
       " exang       0\n",
       " oldpeak     0\n",
       " slope       0\n",
       " ca          0\n",
       " thal        0\n",
       " num         0\n",
       " dtype: int64,\n",
       " age         0\n",
       " sex         5\n",
       " cp          5\n",
       " trestbps    5\n",
       " chol        5\n",
       " fbs         5\n",
       " restecg     5\n",
       " thalach     5\n",
       " exang       5\n",
       " oldpeak     5\n",
       " slope       5\n",
       " ca          5\n",
       " thal        5\n",
       " num         5\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and display the number of missing values for each column in Cleveland and Switzerland datasets\n",
    "miss_cleveland = cleveland.isna().sum()\n",
    "miss_test = test.isna().sum()\n",
    "\n",
    "miss_cleveland, miss_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Missing values of Cleveland & Switzerland data')"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create 1 figure with a set of 2 subplots. Each axes should contain a figure as described below: \n",
    "# subplot 1: A barplot with the missing valies for each attribute in the dataset 'cleveland'\n",
    "# subplot 2: A barplot with the missing valies for each attribute in the dataset 'test'\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(16, 9))\n",
    "\n",
    "cleveland.replace('?', np.nan, inplace=True)\n",
    "test.replace('?', np.nan, inplace=True)\n",
    "\n",
    "miss_cleveland = cleveland.isna().sum()\n",
    "miss_test = test.isna().sum()\n",
    "\n",
    "\n",
    "miss_cleveland.plot(kind='bar', ax=ax[0], color='darkgreen')\n",
    "miss_test.plot(kind='bar', ax=ax[1], color='orange')\n",
    "\n",
    "fig.suptitle('Missing values of Cleveland & Switzerland data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *3.* Imputing categorical variables\n",
    "\n",
    "In the file 'data/heart-disease.names' you can find, together with the names of the columns, a description of their contents.\n",
    "\n",
    "Determine which columns are categorical, and set their type to object.\n",
    "\n",
    "Determine which columns are numerical, and set their type accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    float64\n",
      " 1   sex       303 non-null    float64\n",
      " 2   cp        303 non-null    float64\n",
      " 3   trestbps  303 non-null    float64\n",
      " 4   chol      303 non-null    float64\n",
      " 5   fbs       303 non-null    float64\n",
      " 6   restecg   303 non-null    float64\n",
      " 7   thalach   303 non-null    float64\n",
      " 8   exang     303 non-null    float64\n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    float64\n",
      " 11  ca        299 non-null    object \n",
      " 12  thal      301 non-null    object \n",
      " 13  num       303 non-null    int64  \n",
      "dtypes: float64(11), int64(1), object(2)\n",
      "memory usage: 33.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 122 entries, 0 to 121\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       122 non-null    float64\n",
      " 1   sex       117 non-null    float64\n",
      " 2   cp        117 non-null    float64\n",
      " 3   trestbps  117 non-null    float64\n",
      " 4   chol      117 non-null    float64\n",
      " 5   fbs       46 non-null     object \n",
      " 6   restecg   116 non-null    object \n",
      " 7   thalach   117 non-null    float64\n",
      " 8   exang     117 non-null    float64\n",
      " 9   oldpeak   117 non-null    float64\n",
      " 10  slope     106 non-null    object \n",
      " 11  ca        5 non-null      object \n",
      " 12  thal      66 non-null     object \n",
      " 13  num       117 non-null    float64\n",
      "dtypes: float64(9), object(5)\n",
      "memory usage: 13.5+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cleveland.info()\n",
    "test.info()\n",
    "\n",
    "\n",
    "categorical_columns = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "numerical_columns_int = ['num']\n",
    "numerical_columns_float = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: Split the cleveland dataframe in a train and a validation set. `\n",
    "\n",
    "The train set must be called train, the the validation set must be called val. The size of the validation set must be 30% of the total size of the cleveland dataframe. Use shuffle=True and stratify=True. Make sure that both train and val are dataframes, and that the columns have the correct names. Reset the indexes of all four the dataframes, using drop=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "X_cleveland = cleveland.drop(columns=[\"num\"]) \n",
    "y_cleveland = cleveland[\"num\"]\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_cleveland, y_cleveland, test_size=0.3, shuffle=True, stratify=y_cleveland\n",
    ")\n",
    "\n",
    "# Combine features and target for train and validation sets\n",
    "train = X_train.assign(num=y_train.values)\n",
    "val = X_val.assign(num=y_val.values)\n",
    "\n",
    "# Reset the indexes of train and val dataframes\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "val.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = pd.DataFrame(), pd.DataFrame(), pd.DataFrame(), pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE/CHANGE THIS CELL\n",
    "X_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE/CHANGE THIS CELL\n",
    "X_val.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make the classification task easier, transform the target variable into a binary variable.\n",
    "# If the target variable is 0, it should remain 0. If the target variable is different from 0, it should be transformed into 1.\n",
    "y_train = pd.DataFrame()  # change this\n",
    "y_val = pd.DataFrame()    # change this\n",
    "y_test = pd.DataFrame()   # change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_set_from_franco = pd.read_csv('../../../testing_data/train.csv')\\nval_set_from_franco = pd.read_csv('../../../testing_data/val.csv')\\n\\nassert train.equals(train_set_from_franco), 'train set is not correct'\\nassert val.equals(val_set_from_franco), 'validation set is not correct'\\n\""
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE/CHANGE THIS CELL\n",
    "\n",
    "'''\n",
    "train_set_from_franco = pd.read_csv('../../../testing_data/train.csv')\n",
    "val_set_from_franco = pd.read_csv('../../../testing_data/val.csv')\n",
    "\n",
    "assert train.equals(train_set_from_franco), 'train set is not correct'\n",
    "assert val.equals(val_set_from_franco), 'validation set is not correct'\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: impute the missing values in the categorical columns. Use a KNNImputer from sklearn for the imputation process. `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '!'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20996\\1284452614.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m#  Defining the Imputer with 5 as 'k' and set the weights according to distance measure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mknn_imputer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNNImputer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'distance'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# Fit and transform the train, and transform val and test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mtrain_imputed_knn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn_imputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_cat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_cat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[0mval_imputed_knn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn_imputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_cat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_cat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mtest_imputed_knn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknn_imputer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_cat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_cat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\s0001632\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             return_tuple = (\n",
      "\u001b[1;32mc:\\Users\\s0001632\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1094\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\s0001632\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1471\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1473\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1474\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\s0001632\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_knn.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mforce_all_finite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    231\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\s0001632\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    629\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\s0001632\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    994\u001b[0m                         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m                 raise ValueError(\n\u001b[0;32m   1000\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                 \u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\s0001632\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\s0001632\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     def __array__(\n\u001b[0;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2154\u001b[0m         if (\n\u001b[0;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '!'"
     ]
    }
   ],
   "source": [
    "# 1. Create a subset of the train dataset with only the categorical columns. Call this subset train_cat.\n",
    "# 2. Create a subset of the val dataset with only the categorical columns. Call this subset val_cat.\n",
    "# 3. Create a subset of the test dataset with only the categorical columns. Call this subset test_cat\n",
    "# 4. Impute the three datasets using a KNN imputer with k=5 and weights set to distance\n",
    "# 5. Save the results in train_imputed_knn, val_imputed_knn, and test_imputed_knn.\n",
    "# 6. Make sure to add the column names to the resulting dataframes. DO NOT SKIP THIS STEP.\n",
    "# The new values might have new values that are not in the original dataset.\n",
    "# Approximate them to the nearest value in the original dataset, for each column.\n",
    "# To do so, you can store the original values of each column in a dictionary or a list.\n",
    "# if a new value is equidistant from two original values, choose the largest one.\n",
    "# (Example: if the original values are [1, 3] and the new value is 2, it will become 3)\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Write your code here\n",
    "# Making subsets and picking the categorical_columns defined in task 3\n",
    "\n",
    "train_cat = train[categorical_columns]\n",
    "val_cat = val[categorical_columns]\n",
    "test_cat = test[categorical_columns]\n",
    "                                  \n",
    "train_cat_encoded = train_cat.apply(lambda x: x.astype('category').cat.codes)\n",
    "val_cat_encoded = val_cat.apply(lambda x: x.astype('category').cat.codes)\n",
    "test_cat_encoded = test_cat.apply(lambda x: x.astype('category').cat.codes)\n",
    "\n",
    "\n",
    "#  Defining the Imputer with 5 as 'k' and set the weights according to distance measure\n",
    "knn_imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "\n",
    "# Fit and transform the train, and transform val and test\n",
    "train_imputed_knn = pd.DataFrame(knn_imputer.fit_transform(train_cat), columns=train_cat.columns)\n",
    "val_imputed_knn = pd.DataFrame(knn_imputer.transform(val_cat), columns=val_cat.columns)\n",
    "test_imputed_knn = pd.DataFrame(knn_imputer.transform(test_cat), columns=test_cat.columns)\n",
    "\n",
    "# Looping over the coulns to find take out unique values.\n",
    "original_values = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    original_values[col] = train_cat[col].dropna().unique().tolist()\n",
    "\n",
    "# Looping over each coulmn to round off the imputed values to the nearest valid value.\n",
    "for col in categorical_columns:\n",
    "    train_imputed_knn[col] = train_imputed_knn[col].apply(lambda x: min(original_values[col], key=lambda v: (abs(v - x), -v)))\n",
    "    val_imputed_knn[col] = val_imputed_knn[col].apply(lambda x: min(original_values[col], key=lambda v: (abs(v - x), -v)))\n",
    "    test_imputed_knn[col] = test_imputed_knn[col].apply(lambda x: min(original_values[col], key=lambda v: (abs(v - x), -v)))\n",
    "\n",
    "\n",
    "train_imputed_knn = pd.DataFrame()  # change this\n",
    "val_imputed_knn = pd.DataFrame()    # change this\n",
    "test_imputed_knn = pd.DataFrame()   # change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_imp_knn_franco = pd.read_csv('../../../testing_data/train_imp_knn.csv')\\nval_imp_knn_franco = pd.read_csv('../../../testing_data/val_imp_knn.csv')\\ntest_imp_knn_franco = pd.read_csv('../../../testing_data/test_imp_knn.csv')\\n\\nassert train_imputed_knn.equals(train_imp_knn_franco), 'train imputed knn is not correct'\\nassert val_imputed_knn.equals(val_imp_knn_franco), 'val imputed knn is not correct'\\nassert test_imputed_knn.equals(test_imp_knn_franco), 'test imputed knn is not correct'\\n\""
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE/CHANGE THIS CELL\n",
    "'''\n",
    "train_imp_knn_franco = pd.read_csv('../../../testing_data/train_imp_knn.csv')\n",
    "val_imp_knn_franco = pd.read_csv('../../../testing_data/val_imp_knn.csv')\n",
    "test_imp_knn_franco = pd.read_csv('../../../testing_data/test_imp_knn.csv')\n",
    "\n",
    "assert train_imputed_knn.equals(train_imp_knn_franco), 'train imputed knn is not correct'\n",
    "assert val_imputed_knn.equals(val_imp_knn_franco), 'val imputed knn is not correct'\n",
    "assert test_imputed_knn.equals(test_imp_knn_franco), 'test imputed knn is not correct'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *4.* Imputing numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: impute the missing values in the numerical columns. Use a Lasso Regression from sklearn for the imputation process. `\n",
    "If more than one column contains missing values, proceed in increasing order: the lowest number of missing values first, then the second lowest, then the third ...\n",
    "\n",
    "Exclude the columns with missing values when fitting your regressor: only train on columns without missing values. After a column has been imputed, it can be used to fit the regressor in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "trestbps    0\n",
       "chol        0\n",
       "thalach     0\n",
       "oldpeak     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create a subset of the train dataset with only the numerical columns. Call this subset train_num.\n",
    "# 2. Create a subset of the val dataset with only the numerical columns. Call this subset val_num.\n",
    "# 3. Create a subset of the test dataset with only the numerical columns. Call this subset test_num.\n",
    "# 4a. Create a subset of train_num containing the rows with missing values. Call this subset train_num_missing.\n",
    "# 4b. Create a subset of train_num containing the rows without missing values. Call this subset train_num_not_missing.\n",
    "# 5a. Create a subset of val_num containing the rows with missing values. Call this subset val_num_missing.\n",
    "# 5b. Create a subset of val_num containing the rows without missing values. Call this subset val_num_not_missing.\n",
    "# 6a. Create a subset of test_num containing the rows with missing values. Call this subset test_num_missing.\n",
    "# 6b. Create a subset of test_num containing the rows without missing values. Call this subset test_num_not_missing.\n",
    "# 7. Using a Lasso regression, impute the missing values in train_num_missing, val_num_missing, and test_num_missing.\n",
    "# On what should the Lasso regression be trained?\n",
    "# 8. Repeat steps 1-7 until all the missing values are imputed.\n",
    "# 9. Save the results in train_num_imputed_lasso, val_num_imputed_lasso, and test_num_imputed_lasso.\n",
    "# 10. Concatenate the imputed subsets with the subsets that did not contain missing values.\n",
    "# 11. Save the resulting datasets in train_imputed_lasso, val_imputed_lasso, and test_imputed_lasso.\n",
    "# IMPORTANT: The order of the rows should be the same as in the original datasets.\n",
    "\n",
    "# TEST LASSO:\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "train_num = cleveland[numerical_columns_float]\n",
    "val_num = cleveland[numerical_columns_float]\n",
    "test_num = cleveland[numerical_columns_float]\n",
    "\n",
    "train_num_missing = train_num[train_num.isna().any(axis=1)]\n",
    "train_num_not_missing = train_num.dropna()\n",
    "\n",
    "val_num_missing = val_num[val_num.isna().any(axis=1)]\n",
    "val_num_not_missing = val_num.dropna()\n",
    "\n",
    "test_num_missing = test_num[test_num.isna().any(axis=1)]\n",
    "test_num_not_missing = test_num.dropna()\n",
    "\n",
    "val_num_missing .isna().sum().sort_values()\n",
    "\n",
    "#train_imputed_lasso = pd.DataFrame()  # change this\n",
    "#val_imputed_lasso = pd.DataFrame()    # change this\n",
    "#test_imputed_lasso = pd.DataFrame()   # change this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_num_imputed_lasso' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[151], line 46\u001b[0m\n\u001b[0;32m     42\u001b[0m test_num_not_missing \u001b[38;5;241m=\u001b[39m test_num\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m## Adding the not missing values with the missing values to one data set.\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m train_imputed_lasso \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([train_num_not_missing, train_num_imputed_lasso])\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m     47\u001b[0m val_imputed_lasso \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([val_num_not_missing, val_num_imputed_lasso])\u001b[38;5;241m.\u001b[39msort_index()\n\u001b[0;32m     48\u001b[0m test_imputed_lasso \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([test_num_not_missing, test_num_imputed_lasso])\u001b[38;5;241m.\u001b[39msort_index()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_num_imputed_lasso' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Create a subset of the train dataset with only the numerical columns. Call this subset train_num.\n",
    "# 2. Create a subset of the val dataset with only the numerical columns. Call this subset val_num.\n",
    "# 3. Create a subset of the test dataset with only the numerical columns. Call this subset test_num.\n",
    "# 4a. Create a subset of train_num containing the rows with missing values. Call this subset train_num_missing.\n",
    "# 4b. Create a subset of train_num containing the rows without missing values. Call this subset train_num_not_missing.\n",
    "# 5a. Create a subset of val_num containing the rows with missing values. Call this subset val_num_missing.\n",
    "# 5b. Create a subset of val_num containing the rows without missing values. Call this subset val_num_not_missing.\n",
    "# 6a. Create a subset of test_num containing the rows with missing values. Call this subset test_num_missing.\n",
    "# 6b. Create a subset of test_num containing the rows without missing values. Call this subset test_num_not_missing.\n",
    "# 7. Using a Lasso regression, impute the missing values in train_num_missing, val_num_missing, and test_num_missing.\n",
    "# On what should the Lasso regression be trained?\n",
    "# 8. Repeat steps 1-7 until all the missing values are imputed.\n",
    "# 9. Save the results in train_num_imputed_lasso, val_num_imputed_lasso, and test_num_imputed_lasso.\n",
    "# 10. Concatenate the imputed subsets with the subsets that did not contain missing values.\n",
    "# 11. Save the resulting datasets in train_imputed_lasso, val_imputed_lasso, and test_imputed_lasso.\n",
    "# IMPORTANT: The order of the rows should be the same as in the original datasets.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Anta att train, val och test dataset redan finns definierade\n",
    "\n",
    "# Choosing which vairable that are numerical\n",
    "numerical_columns = ['oldpeak', 'chol', 'age', 'thalach', 'trestbps']\n",
    "\n",
    "# Making subset of the train/validation data set from these numerical varaibles\n",
    "train_num = train[numerical_columns]\n",
    "val_num = val[numerical_columns]\n",
    "test_num = test[numerical_columns]\n",
    "\n",
    "\n",
    "# Subset with and without the missing values (by dropna())\n",
    "train_num_missing = train_num[train_num.isna().any(axis=1)]\n",
    "train_num_not_missing = train_num.dropna()\n",
    "\n",
    "val_num_missing = val_num[val_num.isna().any(axis=1)]\n",
    "val_num_not_missing = val_num.dropna()\n",
    "\n",
    "test_num_missing = test_num[test_num.isna().any(axis=1)]\n",
    "test_num_not_missing = test_num.dropna()\n",
    "\n",
    "\n",
    "## Adding the not missing values with the missing values to one data set.\n",
    "train_imputed_lasso = pd.concat([train_num_not_missing, train_num_imputed_lasso]).sort_index()\n",
    "val_imputed_lasso = pd.concat([val_num_not_missing, val_num_imputed_lasso]).sort_index()\n",
    "test_imputed_lasso = pd.concat([test_num_not_missing, test_num_imputed_lasso]).sort_index()\n",
    "\n",
    "# Reset the indexes of the final imputed datasets\n",
    "train_imputed_lasso.reset_index(drop=True, inplace=True)\n",
    "val_imputed_lasso.reset_index(drop=True, inplace=True)\n",
    "test_imputed_lasso.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Check if 'num' has any missing values\n",
    "print(\"Missing values in 'num' after imputation:\")\n",
    "print(\"Train:\", train_imputed_lasso['num'].isna().sum())\n",
    "print(\"Validation:\", val_imputed_lasso['num'].isna().sum())\n",
    "print(\"Test:\", test_imputed_lasso['num'].isna().sum())\n",
    "\n",
    "#train_imputed_lasso = pd.DataFrame()  # change this\n",
    "#val_imputed_lasso = pd.DataFrame()    # change this\n",
    "#test_imputed_lasso = pd.DataFrame()   # change this\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntrain_imp_lasso_franco = pd.read_csv('../../../testing_data/train_imp_lasso.csv')\\nval_imp_lasso_franco = pd.read_csv('../../../testing_data/val_imp_lasso.csv')\\ntest_imp_lasso_franco = pd.read_csv('../../../testing_data/test_imp_lasso.csv')\\n\\nassert train_imputed_lasso.equals(train_imp_lasso_franco), 'train imputed lasso is not correct'\\nassert val_imputed_lasso.equals(val_imp_lasso_franco), 'val imputed lasso is not correct'\\nassert test_imputed_lasso.equals(test_imp_lasso_franco), 'test imputed lasso is not correct'\\n\""
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT DELETE/CHANGE THIS CELL\n",
    "'''\n",
    "train_imp_lasso_franco = pd.read_csv('../../../testing_data/train_imp_lasso.csv')\n",
    "val_imp_lasso_franco = pd.read_csv('../../../testing_data/val_imp_lasso.csv')\n",
    "test_imp_lasso_franco = pd.read_csv('../../../testing_data/test_imp_lasso.csv')\n",
    "\n",
    "assert train_imputed_lasso.equals(train_imp_lasso_franco), 'train imputed lasso is not correct'\n",
    "assert val_imputed_lasso.equals(val_imp_lasso_franco), 'val imputed lasso is not correct'\n",
    "assert test_imputed_lasso.equals(test_imp_lasso_franco), 'test imputed lasso is not correct'\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *5.* Classification with Decision Tree, using a single split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "212 0\n",
      "Antal rader och kolumner i train_imputed_knn: (212, 8)\n",
      "Antal rader och kolumner i train_imputed_lasso: (212, 6)\n",
      "   sex   cp  fbs  restecg  exang  slope        ca  thal\n",
      "0  1.0  2.0  0.0      0.0    0.0    2.0  0.672241   7.0\n",
      "1  0.0  4.0  0.0      0.0    1.0    2.0  0.000000   3.0\n",
      "2  0.0  2.0  0.0      2.0    0.0    2.0  0.000000   3.0\n",
      "3  1.0  1.0  0.0      2.0    0.0    2.0  0.000000   7.0\n",
      "4  1.0  2.0  0.0      2.0    0.0    1.0  1.000000   3.0\n",
      "    age  trestbps   chol  thalach  oldpeak  num\n",
      "0  58.0     125.0  220.0    144.0      0.4    0\n",
      "1  63.0     124.0  197.0    136.0      0.0    1\n",
      "2  56.0     140.0  294.0    153.0      1.3    0\n",
      "3  59.0     170.0  288.0    159.0      0.2    1\n",
      "4  57.0     154.0  232.0    164.0      0.0    1\n"
     ]
    }
   ],
   "source": [
    "# Merge the train_imputed_knn and train_imputed_lasso datasets. Call the resulting dataset X_train_imputed.\n",
    "# Merge the val_imputed_knn and val_imputed_lasso datasets. Call the resulting dataset X_val_imputed.\n",
    "# Merge the test_imputed_knn and test_imputed_lasso datasets. Call the resulting dataset X_test_imputed.\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "X_train_imputed = pd.concat([train_imputed_knn, train_imputed_lasso], axis=1)\n",
    "X_val_imputed = pd.concat([val_imputed_knn, val_imputed_lasso], axis=1)\n",
    "X_test_imputed = pd.concat([test_imputed_knn, test_imputed_lasso], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: Train a set of Decision Trees, using different hyperparameters. Use the best performing Decision Tree to predict the class for the test set. `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303\n",
      "212\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[552], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m parameter_tree_combination \u001b[38;5;129;01min\u001b[39;00m ParameterGrid(hyperparameters):\n\u001b[0;32m     29\u001b[0m     tree \u001b[38;5;241m=\u001b[39m DT(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparameter_tree_combination)\n\u001b[1;32m---> 30\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X_train_imputed, y_train)\n\u001b[0;32m     31\u001b[0m     y_tree \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mpredict(X_val_imputed)\n\u001b[0;32m     32\u001b[0m     performance\u001b[38;5;241m.\u001b[39mappend(sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mf1_score(y_val, y_tree, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\s0001632\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\s0001632\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1009\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    978\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    979\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    980\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \n\u001b[0;32m    982\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m   1010\u001b[0m         X,\n\u001b[0;32m   1011\u001b[0m         y,\n\u001b[0;32m   1012\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1013\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\s0001632\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\tree\\_classes.py:252\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    248\u001b[0m check_X_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    249\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    250\u001b[0m )\n\u001b[0;32m    251\u001b[0m check_y_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 252\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    253\u001b[0m     X, y, validate_separately\u001b[38;5;241m=\u001b[39m(check_X_params, check_y_params)\n\u001b[0;32m    254\u001b[0m )\n\u001b[0;32m    256\u001b[0m missing_values_in_feature_mask \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_missing_values_in_feature_mask(X)\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n",
      "File \u001b[1;32mc:\\Users\\s0001632\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:648\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m check_y_params:\n\u001b[0;32m    647\u001b[0m         check_y_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdefault_check_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params}\n\u001b[1;32m--> 648\u001b[0m     y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\s0001632\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    875\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    876\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[0;32m    877\u001b[0m )\n\u001b[0;32m    878\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 879\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdtypes_orig)\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m    881\u001b[0m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[0;32m    882\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "# 1. Create a dictionary to contain the hyperparameters. The dictionary should contain the following:\n",
    "# - criterion: 'gini' and 'entropy'\n",
    "# - max_depth: 3, 5, and 7\n",
    "# - min_samples_split: 2, 5, and 10\n",
    "# 2. Create a dictionary called performance to store the hyperparameter combinations and the corresponding performance of the model.\n",
    "# 3. Create a ParameterGrid object with the hyperparameters from the dictionary.\n",
    "# 4. Create a for loop to iterate over the combinations of hyperparameters.\n",
    "# 5. In each iteration\n",
    "# - Create a DecisionTreeClassifier with the hyperparameters for that iteration.\n",
    "# - Fit the model.\n",
    "# - Predict the target variable for the validation set.\n",
    "# - Calculate the F1 score of the model.\n",
    "# - Add the hyperparameters and the F1 score to the performance dictionary.\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.model_selection import GridSearchCV, ParameterGrid\n",
    "from sklearn.metrics import f1_score\n",
    "import time\n",
    "\n",
    "\n",
    "hyperparameters = {'max_depth': [3, 5, 7], 'min_samples_split': [2, 5, 10], 'criterion': ['gini', 'entropy']} # change this\n",
    "# add missing steps here\n",
    "performance = {}\n",
    "\n",
    "for parameter_tree_combination in ParameterGrid(hyperparameters):\n",
    "    tree = DT(**parameter_tree_combination)\n",
    "    tree.fit(X_train_imputed, y_train)\n",
    "    y_tree = tree.predict(X_val_imputed)\n",
    "    performance.append(sklearn.metrics.f1_score(y_val, y_tree, average='macro'))\n",
    "\n",
    "\n",
    "\n",
    "start = time.time() # DO NOT CHANGE/DELETE THIS LINE\n",
    "\n",
    "for number in range(1, 11): # change this\n",
    "    # Add the missing steps here.\n",
    "    pass # remove this line\n",
    "\n",
    "end = time.time() # DO NOT CHANGE/DELETE THIS LINE\n",
    "\n",
    "print('Time elapsed to run the hyperparameter tuning with a single split: ', end - start) # DO NOT CHANGE/DELETE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the best performing hyperparameters\n",
    "best_hyperparameters = None # change this\n",
    "\n",
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the train and validation datasets. Call the resulting datasets X and y.\n",
    "X = pd.DataFrame()  # change this\n",
    "y = pd.DataFrame()  # change this\n",
    "\n",
    "# Create a DecisionTreeClassifier with the best hyperparameters.\n",
    "# Fit the model on the X and y datasets.\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "# Predict the target variable for the test dataset.\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "# Calculate the F1 score of the model on the test dataset. Call the variable f1_test_single_split.\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "f1_test_single_split = None # change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_test_single_split # DO NOT DELETE/CHANGE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *6.* Classification with Decision Tree using Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: Train a cross-validation object, then train a decision tree using cross-validation and different hyperparameters. Use the best performing Decision Tree to predict the class for the test set. `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed to run the hyperparameter tuning with Cross Validation:  0.0019936561584472656\n"
     ]
    }
   ],
   "source": [
    "# 1. Use the same hyperparameters from the previous task.\n",
    "# 2. Create a StratifiedKFold object with 5 splits, use shuffle=True.\n",
    "# 3. Create a dictionary called performance_CV to store the hyperparameter combinations and the corresponding performance of the model.\n",
    "# 3. Create a ParameterGrid object with the usual hyperparameters.\n",
    "# 4. Create a for loop to iterate over the folds of the StratifiedKFold.\n",
    "# 5. For each fold, create a for loop to iterate over the combinations of hyperparameters.\n",
    "# 6. In each iteration\n",
    "# - Create a DecisionTreeClassifier with the hyperparameters for that iteration.\n",
    "# - Fit the model.\n",
    "# - Predict the target variable for the validation fold.\n",
    "# - Calculate the F1 score of the model.\n",
    "# - Add the hyperparameters and the F1 score to the performance dictionary. Each hyperparameter combination may have multiple F1 scores.\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = [[5,6], [10,11], [15,16], [20,21], [25,26], [30,31], [35,36], [40,41], [45,46], [50,51]]    # Delete this line\n",
    "y = [0,1,0,1,0,1,0,1,0,1]                                                                       # Delete this line\n",
    "\n",
    "X = pd.DataFrame(X)                                                                             # Delete this line\n",
    "y = pd.DataFrame(y)                                                                             # Delete this line\n",
    "\n",
    "\n",
    "# DO NOT FORGET TO DELETE THE PREVIOUS LINES. They are only to make the empty assignment run without errors,\n",
    "# but they will destroy the data you need.\n",
    "\n",
    "\n",
    "CV = StratifiedKFold() # change this\n",
    "\n",
    "hyperparameters = None # change this\n",
    "# add missing steps here\n",
    "\n",
    "start_CV = time.time() # DO NOT CHANGE/DELETE THIS LINE\n",
    "\n",
    "for i, (train_index, val_index) in enumerate(CV.split(X, y)):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "    for number in range(1, 11): # change this\n",
    "        # Add the missing steps here.\n",
    "        pass # remove this line\n",
    "\n",
    "end_CV = time.time() # DO NOT CHANGE/DELETE THIS LINE\n",
    "\n",
    "print('Time elapsed to run the hyperparameter tuning with Cross Validation: ', end_CV - start_CV) # DO NOT CHANGE/DELETE THIS LINE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the best performing hyperparameters, which are the ones with the highest average F1 score\n",
    "best_hyperparameters_CV = None # change this\n",
    "\n",
    "best_hyperparameters_CV # DO NOT DELETE/CHANGE THIS LINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DecisionTreeClassifier with the best hyperparameters.\n",
    "# Fit the model on the X and y datasets.\n",
    "# Call the fitted model final_tree.\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "# Predict the target variable for the test dataset.\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "# Calculate the F1 score of the model on the test dataset. Call the variable f1_test_CV.\n",
    "\n",
    "# Write your code here\n",
    "\n",
    "f1_test_CV = None # change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_test_CV # DO NOT DELETE/CHANGE THIS LINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *7.* Interpretation of the results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: Look at the times elapsed to train the Decision Tree using the single split and the CV strategies. Is there a difference? Explain the difference or the lack of difference in 50 words or less. `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your explanation here. Delete this text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ` Task: Plot final_tree, and explain which feature or combination of features is the most relevant for that model, in 50 words or less. `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find instructions on how to plot a decision tree at [this link](https://scikit-learn.org/stable/auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot your tree here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your explanation here. Delete this text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
